\documentclass[12pt]{article}%
\usepackage{amsfonts}
\usepackage{fancyhdr}
\usepackage[hidelinks]{hyperref}
\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=2.2cm, right=2.2cm]%
{geometry}
\usepackage{times}
\usepackage{amsmath}
\usepackage{amsthm}
\let\proof\relax
\let\endproof\relax
\usepackage{changepage}
\usepackage{amssymb}
\usepackage{graphicx}%
\usepackage{enumitem}
\usepackage{tikz}
\setcounter{MaxMatrixCols}{30}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newenvironment{proof}[1][Proof]{\textbf{#1.} }{\ \rule{0.5em}{0.5em}}

\begin{document}

\title{COS 445 - Warmup PSet} %Replace X with homework number, Y with problem number.
\author{Hieronymus Bosch} %Write your name here
\date{\today}
\maketitle

\section*{Problem 1: Basic Probability I}
\begin{enumerate}[label=(\alph*)]
\item We wish to compute the expectation of the discrete random variable $X$, where $X = i$ with probability $2^{-i}$, for all integers $i \ge 1$.

By definition, the expected value of $X$ (form 1) is 

\begin{equation}
\mathbb{E}[X] = \sum_{i = 0}^{\infty} \Pr[X = i] \cdot i
\end{equation}

We are given that $X = i$ with probability $2^{-i}$, so we can rewrite the expectation of $X$ as

\begin{equation}
\mathbb{E}[X] = \sum_{i = 0}^{\infty} 2^{-i} \cdot i
\end{equation}

This infinite series evaluates to $\mathbb{E}[X] = 2$.

\item We wish to compute the expectation of the non-negative, continuous random variable $Y$ with CDF $F_Y(x) = 1 - \frac{1}{(x + 1)^3}, x \ge 0$.

By definition, the expected value of continuous random variables (form 1) is

\begin{equation}
\mathbb{E}[Y] = \int_{0}^{\infty} (1- F(x))dx
\end{equation}

The CDF of $Y$, $F_Y(x)$ is given to us, and so can be used to evaluate the integral:

\begin{equation}
\begin{split}
\mathbb{E}[Y] &= \int_{0}^{\infty} (1- (1 - \frac{1}{(x + 1)^3}))dx \\
&= \int_{0}^{\infty} \frac{1}{(x + 1)^3}dx
\end{split}
\end{equation}

Let $u = x + 1$, with $u = 1$ when $x = 0$. After substitution, we have

\begin{equation}
\begin{split}
\mathbb{E}[Y] &= \int_{1}^{\infty} \frac{1}{u^3}dx \\
&= -\frac{1}{2u^2} \Biggr|_{1}^{\infty}
\end{split}
\end{equation}

Finally, we can evaluate the limits:

\begin{equation}
\lim_{b \to +\infty} -\frac{1}{2u^2} \Biggr|_{1}^{b} = -\frac{1}{2 \cdot \infty} - -\frac{1}{2 \cdot 1} = \frac{1}{2}
\end{equation}

The expectation of $Y$ is therefore $\frac{1}{2}$.

\item We wish to compute the expectation of the random variable $Z = X + Y$.

By linearity of expectation, $\mathbb{E}[X + Y] = \mathbb{E}[X] + \mathbb{E}[X]$. Using values computed in the two previous questions, the expectation of $Z$ can be written as

\begin{equation}
\mathbb{E}[Z] = \mathbb{E}[X + Y] = \mathbb{E}[X] + \mathbb{E}[X] = 2 + \frac{1}{2}.
\end{equation}

The expectation of $Z$ is therefore 2.5.
\end{enumerate}

\section*{Problem 2: Basic Probability II}
\begin{enumerate}[label=(\alph*)]
\item We wish to find the probability that Bin 1 is empty.

It is given that each ball is thrown independently into a uniformly random bin. Since there are $n$ bins, this means the probability of a thrown ball landing into a given bin is $\frac{1}{n}$. The probability that a thrown ball does \emph{not} land into a given bin is then $1 - \frac{1}{n}$.

Since there are also $n$ balls, and each throw is independent, Bin 1 is empty with probability $(1 - \frac{1}{n})^n$. In other words, it is the probability that all $n$ throws do not land in the bin.

\item We wish to find the expected number of empty bins. From the previous question, we know that $\Pr[X_i = 1] = (1 - \frac{1}{n})^n$.

Since there are $n$ bins, the expected number of empty bins is $n \cdot (1 - \frac{1}{n})^n$.

\item We wish to find the expected number of bins which contain exactly two balls.

There are $\binom{n}{2}$ ways to choose two balls out of the $n$ bins. From the first part, the probability a ball lands in a given bin $\frac{1}{n}$. Therefore, the probability that \emph{two} balls land in a given bin is $\frac{1}{n^2}$. Additionally, the probability that a bin is empty after all $n$ throws is $(1 - \frac{1}{n})^n$. This means that the probability that the other $n - 2$ balls do not land in a given bin is $(1 - \frac{1}{n})^{n - 2}$.

The probability a given bin has exactly two balls is therefore $\binom{n}{2} \cdot \frac{1}{n^2} \cdot (1 - \frac{1}{n})^{n - 2}$. Since there are $n$ bins, the expected number of bins with exactly two balls is $n \cdot (\binom{n}{2} \cdot \frac{1}{n^2} \cdot (1 - \frac{1}{n})^{n - 2})$ or more simply $\binom{n}{2} \cdot \frac{(n - 1)^{n - 2}}{n^{n - 1}}$.
\end{enumerate}

\section*{Problem 3: Basic Continuous Optimization}
\begin{enumerate}[label=(\alph*)]
\item We wish to minimize $f(x_1,x_2) = x_{1}^{2} - x_{1}x_{2} + x_{2}^{2}$ over all $(x_1,x_2) \in \mathbb{R}^2$.

We first calculate a partial derivative by holding $x_2$ constant:

\begin{equation}
\frac{\partial f}{\partial x_1} = 2x_1 - x_2
\end{equation}

It then follows that the unique minimizer is at $x_2 = 2x_1$, which can be substituted into the function to optimize:

\begin{equation}
\begin{split}
f(x_1,x_2) &= x_{1}^{2} - x_{1}x_{2} + x_{2}^{2} \\
&= x_{1}^{2} - 2x_{1}^{2} + 4x_{1}^{2} \\
&= 3x_{1}^{2}
\end{split}
\end{equation}

Since this is just the product of a constant and $x^2$, it is clearly minimized at $x_1 = 0$. Therefore, the unique global minimizer is $(0,0)$.

\item We wish to maximize $f(x_1,x_2) = x_1 - x_2 + x_{1}x_{2}$ over the range $[-1,1] \times [-1, 1]$.

We first calculate a partial derivative by holding $x_2$ constant:

\begin{equation}
\frac{\partial f}{\partial x_1} = 1 + x_2
\end{equation}

It then follows that $x_2 = -1$, which can be substituted into the function to optimize:

\begin{equation}
\begin{split}
f(x_1,x_2) &= x_1 - x_2 + x_{1}x_{2} \\
&= x_1 + 1 + -x_1 \\
&= 1
\end{split}
\end{equation}

This is a constant, which means graphically that the function will be drawn as a line segment. In other words, when $x_2 = -1$ the function will be maximized for any value of $x_1$. The same is true when a partial derivative is formed by holding $x_1$ constant:

\begin{equation}
\frac{\partial f}{\partial x_2} = -1 + x_1
\end{equation}

It then follows that $x_1 = 1$, which can be substituted into the function to optimize:

\begin{equation}
\begin{split}
f(x_1,x_2) &= x_1 - x_2 + x_{1}x_{2} \\
&= 1 - x_2 + x_2 \\
&= 1
\end{split}
\end{equation}

This again produces a constant, meaning the function will be maximized for any value of $x_2$ when $x_1 = 1$.

\end{enumerate}

\section*{Problem 4: Basic Proofs I}
We wish to prove that the expected number of packs that need to be purchased to have at least one copy of each of the $n$ cards is $\Theta(n \log n)$.

We first examine the probability of pulling a single, \emph{distinct} card. Intuitively, the first card pack will always be distinct. If there are $n$ distinct cards, a uniformly random chance of pulling each card, and no cards have been pulled, the probability of a distinct card is $\frac{n}{n} = 1$. Each distinct card that is pulled reduces the probability that the next card is also distinct. The probability of the second card being distinct, for example, is $\frac{n - 1}{n}$. In general, the probability of the next distinct card is $\frac{n - i}{n}$ where $i$ is the number of distinct cards already drawn.

We note that if a coin is heads with probability $p$, the expected number of flips until seeing a heads is $\frac{1}{p}$. Given that the $i$-th distinct card is found with probability $p_i = \frac{n - i}{n}$, it follows that the expected number of packs needed will be $\frac{1}{\frac{n - i}{n}} = \frac{n}{n - i}$.

Let $X$ represent the number of packs that need to be bought in order to obtain all $n$ distinct cards. The expectation of $X$ can then be calculated as

\begin{equation}
\begin{split}
\mathbb{E}[X] &= \frac{1}{p_0} + \frac{1}{p_1} + \frac{1}{p_2} + \cdots + \frac{1}{p_n} \\
&= \frac{n}{n - 0} +  \frac{n}{n - 1} +  \frac{n}{n - 2} + \cdots +  \frac{n}{1} \\
&= n \cdot (\frac{1}{n - 0} +  \frac{1}{n - 1} +  \frac{1}{n - 2} + \cdots +  \frac{1}{1}) \\
&= n \cdot (\frac{1}{1} +  \frac{1}{2} +  \frac{1}{3} + \cdots +  \frac{1}{n}) \\
&= n \cdot \sum_{i = 1}^{n} \frac{1}{i}
\end{split}
\end{equation}

We note that $\ln (n + 1) + 1 > \sum_{i = 1}^{n} \frac{1}{i} > \ln (n + 1)$, so the expectation of $X$ must be similarly bounded since $\mathbb{E}[X]$ is equal to $\sum_{i = 1}^{n} \frac{1}{i}$ times $n$. Therefore, $E[X]$ must be $\Theta(n \log n)$.

\section*{Problem 5: Basic Proofs II}
We wish to prove that if six people are together in a room, there is either a buddy-full set of size 3 or a buddy-free set of size 3.

We begin by considering the problem in terms of a graph. Each person in the room can be represented by a single vertex. Because each person has two possible relationship states with everyone else (they are buddies or not buddies), an edge can be drawn between every vertex. This produces a complete graph. Let the color red signify an edge between two buddies and let the color blue signify an edge between two non-buddies. If a red or blue triangle exists between three vertices, it means there is either a buddy-full set of size 3 or a buddy-free set of size 3.

There are six vertices and the graph is complete, so are five edges coming from each vertex. Because there are five edges and only two possible colors (red and blue), there are either at least three red edges or at least three blue edges from a vertex. This follows from the pigeonhole principle. 

We consider three red edges from a vertex in the graph and the associated three vertices connected to each edge. If any pair of the associated three vertices is connected by a red edge, than a red triangle is created. If no pair exists with a red edge, then the three vertices must all have blue edges between each other and thus a blue triangle. A similar observation is made if the first three edges considered were blue. Therefore, in a room of six people there is either a buddy-full set of size 3 or a buddy-free set of size 3.

To prove that if there are only five people in the room it is possible there is \emph{neither a buddy-full set of size 3 nor a buddy-free set of size 3}, we can simply provide a graph coloring that meets this criteria:

\begin{center}
\newcommand\size{3}% distance of nodes from center
\begin{tikzpicture}
  \draw[thick,red]  (18:\size) \foreach \a in {90,162,234,306} { -- (\a:\size) } -- cycle;
  \draw[thick,blue] (18:\size) \foreach \a in {162,306,90,234} { -- (\a:\size) } -- cycle;
  \foreach \a in {18,90,162,234,306} { \node[black,fill=black,circle,inner sep=2pt] at (\a:\size){}; }
\end{tikzpicture}
\end{center}

As shown in the graph, each vertex is still connected to every other vertex. However, no triangles of the same color exist, showing it is possible in a room of five people to have neither a buddy-full set of size 3 nor a buddy-free set of size 3.

\end{document}
